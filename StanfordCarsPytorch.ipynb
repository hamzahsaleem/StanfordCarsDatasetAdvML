{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StanfordCarsPytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzahsaleem/StanfordCarsDatasetAdvML/blob/master/StanfordCarsPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqeS0AJOMK7v",
        "colab_type": "code",
        "outputId": "88d25b0e-e7ed-4745-ed9a-4df8027b2d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install opencv-python\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import json\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "import os\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "import torchvision\n",
        "import time\n",
        "from IPython.display import display\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.2)\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwDntv1MpCly",
        "colab_type": "code",
        "outputId": "ba11cc88-fdbd-4aa4-8d4b-5e9b0302f98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9G7X_cEMRGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/drive/My Drive/stanford-car-dataset-by-classes/car_data/car_data'\n",
        "train_dir = data_dir + '/train'\n",
        "test_dir = data_dir + '/test'\n",
        "\n",
        "original_pixel_size = 350 \n",
        "resized_pixel_size = 350\n",
        "total_classes = 196"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPqMQZy-ggL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FGSM attack code\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    # Adding clipping to maintain [-1,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, -1, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ0lgTsJgwZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test( model, device, test_loader, epsilon ):\n",
        "\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    wrong_test = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        # Send the data and label to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Forward pass the data through the model\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "          wrong_test+=1\n",
        "          continue\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        # Zero all existing gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Collect datagrad\n",
        "        data_grad = data.grad.data\n",
        "\n",
        "        # Call FGSM Attack\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "        else:\n",
        "            # Save some adv examples for visualization later\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "    #print(\"Test Accuracy: \"+ str(((len(test_loader)-wrong_test)*100)/float(len(test_loader))))\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = (correct*100)/float(len(test_loader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "    \n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_vrHpcZMaff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training transform includes random rotation and flip to build a more robust model\n",
        "train_tfms = transforms.Compose([transforms.Resize((resized_pixel_size, resized_pixel_size)),\n",
        "                                 transforms.Resize((original_pixel_size, original_pixel_size)),\n",
        "                                 transforms.RandomHorizontalFlip(),\n",
        "                                 transforms.RandomRotation(15),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# The validation set will use the same transform as the test set\n",
        "test_tfms = transforms.Compose([transforms.Resize((resized_pixel_size, resized_pixel_size)),\n",
        "                                transforms.Resize((original_pixel_size, original_pixel_size)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset = datasets.ImageFolder(root=train_dir, transform = train_tfms)\n",
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True, num_workers = 2)\n",
        "\n",
        "dataset2 = datasets.ImageFolder(root=test_dir, transform = test_tfms)\n",
        "testloader = torch.utils.data.DataLoader(dataset2, batch_size = 32, shuffle=False, num_workers = 2)\n",
        "testloader_adversarial = torch.utils.data.DataLoader(dataset2, batch_size = 1, shuffle=False, num_workers = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1iv8sHC8Foc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(model):\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testloader, 0):\n",
        "            images, labels = data\n",
        "            #images = images.to(device).half() # uncomment for half precision model\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model_ft(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100.0 * correct / total\n",
        "    print('Accuracy of the network on the test images: %d %%' % (\n",
        "        test_acc))\n",
        "    return test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQnqqPRx7tDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    test_accuracies = []\n",
        "    # set the model to train mode initially\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "        since = time.time()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "            # get the inputs and assign them to cuda\n",
        "            inputs, labels = data\n",
        "            #inputs = inputs.to(device).half() # uncomment for half precision model\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # calculate the loss/acc later\n",
        "            running_loss += loss.item()\n",
        "            running_correct += (labels==predicted).sum().item()\n",
        "\n",
        "        epoch_duration = time.time()-since\n",
        "        epoch_loss = running_loss/len(trainloader)\n",
        "        epoch_acc = 100/32*running_correct/len(trainloader)\n",
        "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
        "        \n",
        "        losses.append(epoch_loss)\n",
        "        accuracies.append(epoch_acc)\n",
        "        \n",
        "        # switch the model to eval mode to evaluate on test data\n",
        "        model.eval()\n",
        "        test_acc = eval_model(model)\n",
        "        test_accuracies.append(test_acc)\n",
        "        \n",
        "        # re-set the model to train mode after validating\n",
        "        model.train()\n",
        "        scheduler.step(test_acc)\n",
        "        since = time.time()\n",
        "    print('Finished Training')\n",
        "    return model, losses, accuracies, test_accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks3PVkaUM_to",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = models.resnet34(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "# replace the last fc layer with an untrained one (requires grad by default)\n",
        "model_ft.fc = nn.Linear(num_ftrs, total_classes)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# uncomment this block for half precision model\n",
        "\"\"\"\n",
        "model_ft = model_ft.half()\n",
        "\n",
        "\n",
        "for layer in model_ft.modules():\n",
        "    if isinstance(layer, nn.BatchNorm2d):\n",
        "        layer.float()\n",
        "\"\"\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "\"\"\"\n",
        "probably not the best metric to track, but we are tracking the training accuracy and measuring whether\n",
        "it increases by atleast 0.9 per epoch and if it hasn't increased by 0.9 reduce the lr by 0.1x.\n",
        "However in this model it did not benefit me.\n",
        "\"\"\"\n",
        "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFfqTUYTQS31",
        "colab_type": "code",
        "outputId": "c113c5b2-2e1d-449d-d009-f5cae0ccdec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, duration: 84 s, loss: 3.8560, acc: 17.5245\n",
            "Accuracy of the network on the test images: 38 %\n",
            "Epoch 2, duration: 84 s, loss: 1.6017, acc: 56.9363\n",
            "Accuracy of the network on the test images: 57 %\n",
            "Epoch 3, duration: 82 s, loss: 0.8391, acc: 76.6422\n",
            "Accuracy of the network on the test images: 64 %\n",
            "Epoch 4, duration: 83 s, loss: 0.5477, acc: 84.5711\n",
            "Accuracy of the network on the test images: 76 %\n",
            "Epoch 5, duration: 83 s, loss: 0.3478, acc: 89.9877\n",
            "Accuracy of the network on the test images: 77 %\n",
            "Epoch 6, duration: 83 s, loss: 0.2479, acc: 93.1127\n",
            "Accuracy of the network on the test images: 80 %\n",
            "Epoch 7, duration: 84 s, loss: 0.1894, acc: 94.5833\n",
            "Accuracy of the network on the test images: 81 %\n",
            "Epoch 8, duration: 85 s, loss: 0.1420, acc: 96.2132\n",
            "Accuracy of the network on the test images: 84 %\n",
            "Epoch 9, duration: 84 s, loss: 0.0644, acc: 98.3946\n",
            "Accuracy of the network on the test images: 89 %\n",
            "Epoch 10, duration: 84 s, loss: 0.0448, acc: 98.9583\n",
            "Accuracy of the network on the test images: 89 %\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZSgrWJThPoR",
        "colab_type": "code",
        "outputId": "4d387ba2-fdda-4cf9-962e-be4872938a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_ft.eval()\n",
        "eps = 0.01\n",
        "acc, ex = test(model_ft, torch.device(\"cuda\"), testloader_adversarial, eps)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0.01\tTest Accuracy = 2390 / 8041 = 29.722671309538615\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}